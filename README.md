# Приложение для построения моделей Forest Cover Type Prediction
Задание в рамках RS School Machine Learning course 2022
## Установка
1. Клонируйте (clone) репозиторий на локальную машину.
2. Скачайте датасет [Forest Cover Type Prediction](https://www.kaggle.com/competitions/forest-cover-type-prediction/data), сохранив его на локальной машине (путь по умолчанию: *data/heart.csv* в корневой папке репозитория).
3. Убедитесь, что Python 3.9 и [Poetry](https://python-poetry.org/docs/) установлены на вашей локальной машине.
4. Чтобы установить зависимости проекта, перейдите в корневую папку клонированного репозитория и запустите оттуда следующую команду:
```
poetry install --no-dev
```
## Запуск интерфейса
1. Из корневой папки репозитория запустите следующую команду:
```
poetry run ml
```
2. В любое время с помощью команды **?** или **help** на экран можно вывести все доступные команды. Справка по отдельной команде доступна при добавлении аргумента -h:
```
>>> scaler -h
Usage: scaler [-h] {none, standard, minmax, maxabs, robust}

positional arguments:
    {none, standard, minmax, maxabs, robust}
        Выберите один из доступных алгоритмов машстабирования данных или отключите его (none).
```
3. Интерфейс командной строки поддерживает автозаполнение по нажатию клавиши **Tab**: вместо того, чтобы печатать команду *scaler standard*, достаточно напечатать *sc* -> [Tab] -> *s* -> [Tab].

## Настройка алгоритма и препроцессинг
1. Выберите алгоритм, который будет использоваться при обучении, при помощи команды **setmodel**. Это обязательный этап, в то время как все последующие команды этого раздела опциональны. Доступны следующие алгоритмы:
* logit (логистическая регрессия)
* tree (дерево решений)
* forest (случайный лес)
* knn (k-ближайших соседей)
```
setmodel knn
```
2. При необходимости с помощью команды **scaler** задайте алгоритм для масштабирования данных (доступные алгоритмы: standard, minmax, maxabs, robust; без масштабирования: none):
```
scaler standard
```
3. При необходимости с помощью команды **dimreduct** задайте алгоритм для уменьшения размерности данных (доступные алгоритмы: pca, lda; без снижения размерности: none):
```
dimreduct pca
```
4. При необходимости с помощью команды **feateng** можно включить автоматический feature engineering, алгоритм которого был создан специально для указанного выше датасета. В отличие от предыдущих опций, эта команда сразу запускает процесс создания новых признаков, поэтому ее выполнение может занять время. Вернуться к оригинальному датасету можно при помощи команды *feateng none*.
```
feateng auto
```
5. Обратите внимание, что все настройки этого раздела сохраняются до тех пор, пока явно не будут изменены соответствующими командами или пока интерфейс не будет закрыт.
## Другие настройки
Как правило, изменять значения этих настроек, установленные по умолчанию, нет нужды. Но при желании следующие команды позволяют задать пользовательские значения:
* **setpath load** *input_file* (где input_file - путь к анализируемому датасету, отличный от пути по умолчанию)
* **setpath dump** *input_file* (где input_file - путь к файлу joblib, отличный от пути по умолчанию)
* **paths** (просмотр значений установленных путей)
* **targetcolumn** *column_name* (где column_name - название столбца с независимой переменной в анализируемом датасете)
* **randomstate** *seed* (где seed - число, определяющее начальное состояние генератора случайных чисел)

## Построение модели с ручным подбором гиперпараметров
1. Для того, чтобы построить модель, воспользуйтесь командой **train**. В отсутствие аргументов будут использованы параметры по умолчанию:
```
>>> train
Строим модель knn c параметрами {'n_neighbors': 5, 'weights': 'uniform'} (scaler: none, feateng: none, dimreduct: none)...
Успешно! Accuracy (balanced): 0.8111
```
2. Команда **train** принимает опциональные аргументы, перечень которых зависит от выбранного алгоритма. Для того чтобы увидеть перечень встроенных аргументов, выполните команду *train -h*:
```
>>> train -h
Usage: train [-h] [-k N_NEIGHBORS] [-w {uniform, distance}]
optional arguments:
    -h, --help            show this help message and exit
    -k, --n_neighbors N_NEIGHBORS
        количество ближаших объектов, оцениваемых при классификации [по умолчанию: 5]
    -w, --weights {uniform, distance}
        функция взвешивания [по умолчанию: uniform]
```
```
>>> train -k 10
(Cmd) train -k 10
Строим модель knn c параметрами {'n_neighbors': 10, 'weights': 'uniform'} (scaler: none, feateng: none, dimreduct: none)...
Успешно! Accuracy (balanced): 0.7811
```
3. Команда train также может принимать и неизвестные ей аргументы, если их значение представляет собой число, строку, *True*/*False* или *None*. В таком случае название аргумента должно начинаться с двух дефисов (--) и полностью совпадать с названием соответствующего параметра этого класса sklearn, как например для [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html).
```
>>> train -k 10 --metric manhattan --leaf_size 10
Строим модель knn c параметрами {'metric': 'manhattan', 'leaf_size': 10, 'n_neighbors': 10, 'weights': 'uniform'} (scaler: none, feateng: none, dimreduct: none)...
Успешно! Accuracy (balanced): 0.8034
```
## Построение модели с автоматическим подбором гиперпараметров
1. Для автоматического подбора гиперпараметров воспользуйтесь командой **hypersearch**. В отсутствие аргументов поиск будет проведен по сетке параметров, установленной для этого алгоритма по умолчанию.
```
>>> hypersearch
Оцениваем алгоритм и гиперпараметры...
Метрики оцениваемого алгоритма (метод оценки - nested cross-validation): accuracy (balanced): 0.8223, F1 (weighted): 0.8172, ROC AUC (ovo): 0.9649. Модель: knn, scaler: none, dimreduct: none, feateng: none
Лучший набор параметров из исследованных GridSearch: {'clf__leaf_size': 10, 'clf__n_neighbors': 5}
```
2. Возможно также задать собственную сетку для подбора гиперпараметров. Для этого используется аргумент **-p** со значением, представляющим собой текстовую запись словаря (dict), ограниченную с обеих сторон фигурными скобками и не содержащую пробелов, например:
```
 >>> hypersearch -p {"n_neighbors":[4,6,10],"metric":["euclidean","chebyshev"]}
Оцениваем алгоритм и гиперпараметры...
Метрики оцениваемого алгоритма (метод оценки - nested cross-validation): accuracy (balanced): 0.8274, F1 (weighted): 0.8231, ROC AUC (ovo): 0.9621. Модель: knn, scaler: none, dimreduct: none, feateng: none
Лучший набор параметров из исследованных GridSearch: {'clf__metric': 'euclidean', 'clf__n_neighbors': 4}
```

## Просмотр результатов в MLflow
1. Параметры и метрики построенных моделей доступны для просмотра в **MLFlow**. Чтобы запустить интерфейс, выполните указанную ниже команду, а затем перейдите в браузере по полученному адресу.
```
poetry run mlflow ui
```
2. При использовании функции hypersearch **источником данных** для сохранения в MLflow служат:
* параметры - лучшие параметры, найденные при исполнении GridSearchCV с использованием всех данных датасета
* метрики - средние метрики, полученные в ходе процедуры Nested cross-validation

## Примеры подбора параметров в MLflow (задания 8 и 9)
### Модели логистической регрессии
![Logit](img/mlflow_logit.png?raw=true "Logit")
### Модели KNN
![KNN](img/mlflow_knn.png?raw=true "KNN")
### Автоматический подбор параметров и оценка алгоритма в Nested CV
![Nested CV](img/mlflow_hypersearch.png?raw=true "Nested CV")

## Средства разработчика
1. Чтобы установить все средства разработки, выполните следующую команду:
```
poetry install
```
2. Теперь вам доступны следующие инструменты, запускающиеся командой *poetry run <name>*:
* mypy
* black
* flake8
* pytest

3. Запустить все средства разработки можно при помощи одной команды:
```
poetry run nox
```
![nox](img/nox_session.png?raw=true "nox")

4. Mypy и flake8 также автоматически запускаются при каждом push в репозиторий. Убедиться в этом можно на вкладке проекта "Actions".